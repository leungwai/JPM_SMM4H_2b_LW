{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leung Wai Liu <br>\n",
    "JPMC-SMM4H <br>\n",
    "July 14, 2022 <br>\n",
    "Task 2a TEST Weighted Average Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from labels_to_ids import task7_labels_to_ids\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from training_code import calculate_overall_performance_metrics\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>bert-large-uncased</th>\n",
       "      <th>roberta-large</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.788181</td>\n",
       "      <td>0.805198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.798593</td>\n",
       "      <td>0.789957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.771915</td>\n",
       "      <td>0.777964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.813640</td>\n",
       "      <td>0.796570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.784882</td>\n",
       "      <td>0.782647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  bert-large-uncased  roberta-large\n",
       "0           0            0.788181       0.805198\n",
       "1           1            0.798593       0.789957\n",
       "2           2            0.771915       0.777964\n",
       "3           3            0.813640       0.796570\n",
       "4           4            0.784882       0.782647"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading up all the predictions data\n",
    "\n",
    "n_rnds = 5\n",
    "original_df = pd.read_csv('../Datasets/test.tsv', sep='\\t')\n",
    "models = ['bert-large-uncased', 'roberta-large']\n",
    "n_models = len(models)\n",
    "\n",
    "epoch_string = '../15_epochs_large_model/saved_test_result_2b_final'\n",
    "n_rows = len(original_df)\n",
    "\n",
    "labels_to_ids = task7_labels_to_ids\n",
    "ids_to_labels = dict((v,k) for k,v in labels_to_ids.items())\n",
    "\n",
    "# Loading up all of the results\n",
    "best_f1 = pd.read_csv('../15_epochs_large_model/eval_testing/validation_stats/all_best_overall_f1_score.tsv', sep='\\t')\n",
    "best_f1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieving all the predictions from the \n",
    "list_of_df = []\n",
    "list_of_f1_score = []\n",
    "sum_of_all_f1_score = 0\n",
    "\n",
    "for model in models: \n",
    "    specific_model_row = []\n",
    "    specific_model_row_f1 = []\n",
    "    for rnd in range(n_rnds):\n",
    "        to_read_string = epoch_string + '/' + model + '/' + str(rnd) + '/unformatted_test_result.tsv'\n",
    "        \n",
    "        specific_f1_score = best_f1.at[rnd, model]\n",
    "        specific_model_row_f1.append(specific_f1_score)\n",
    "        sum_of_all_f1_score += specific_f1_score\n",
    "        \n",
    "        particular_model_df = pd.read_csv(to_read_string, sep='\\t')\n",
    "        specific_model_row.append(particular_model_df)\n",
    "    \n",
    "    list_of_df.append(specific_model_row)\n",
    "    list_of_f1_score.append(specific_model_row_f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TAKING THE WEIGHTED AVERAGE OF DATA\n",
    "\n",
    "weighted_avg_original_tweet_id_list = []\n",
    "weighted_avg_original_sentence_list = []\n",
    "weighted_avg_original_claim_list = []\n",
    "\n",
    "weighted_avg_predicted_results = []\n",
    "\n",
    "\n",
    "for index, row in original_df.iterrows(): \n",
    "    # getting the original values in the tweet\n",
    "    original_tweet_id = row['id']\n",
    "    original_sentence = row['text']\n",
    "    original_claim = row['claim']\n",
    "    \n",
    "    # transferring the labels over to final list\n",
    "    weighted_avg_original_tweet_id_list.append(original_tweet_id)\n",
    "    weighted_avg_original_sentence_list.append(original_sentence)\n",
    "    weighted_avg_original_claim_list.append(original_claim)\n",
    "    \n",
    "    specific_row_value = 0.0\n",
    "    # go through every models' row of data \n",
    "    \n",
    "    for model_num in range(n_models):\n",
    "        for rnd_num in range(n_rnds):\n",
    "\n",
    "            particular_row_df = list_of_df[model_num][rnd_num]\n",
    "            row = particular_row_df.loc[(particular_row_df['id'] == original_tweet_id)]\n",
    "\n",
    "            prediction = row['Premise'].values[0] * list_of_f1_score[model_num][rnd_num]\n",
    "            specific_row_value += prediction\n",
    "\n",
    "    specific_row_value = specific_row_value / sum_of_all_f1_score\n",
    "    specific_row_result = int(round(specific_row_value))\n",
    "    weighted_avg_predicted_results.append(specific_row_result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>Claim</th>\n",
       "      <th>Premise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1307558525371965442</td>\n",
       "      <td>@narendramodi @rajnathsingh Student ka bhi soa...</td>\n",
       "      <td>school closures</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1247739239879467009</td>\n",
       "      <td>—échale un vistazo a esto…   … a fair piece on...</td>\n",
       "      <td>stay at home orders</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1242046510155653125</td>\n",
       "      <td>Why do think skilling women and girls is impor...</td>\n",
       "      <td>stay at home orders</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1358446499949084675</td>\n",
       "      <td>To reduce the risk of the virus spreading as e...</td>\n",
       "      <td>school closures</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1249740062775902208</td>\n",
       "      <td>I speak for a great many people when i say WE ...</td>\n",
       "      <td>stay at home orders</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9950</th>\n",
       "      <td>1242516037628813314</td>\n",
       "      <td>StayAtHomeSaveLives 21daysLockdown StayAtHome ...</td>\n",
       "      <td>stay at home orders</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9951</th>\n",
       "      <td>1242746919933415424</td>\n",
       "      <td>If this is true this is heartbreaking StayAtHo...</td>\n",
       "      <td>stay at home orders</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9952</th>\n",
       "      <td>1276638598813679617</td>\n",
       "      <td>855 Sunset Cove Dr, Winter Haven, FL 33880 3 B...</td>\n",
       "      <td>stay at home orders</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9953</th>\n",
       "      <td>1243504288661270528</td>\n",
       "      <td>StayAtHomeSaveLives StayHomeStaySafe StayHome ...</td>\n",
       "      <td>stay at home orders</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9954</th>\n",
       "      <td>1237875841981247488</td>\n",
       "      <td>We’re on track to be like Italy is now. Time t...</td>\n",
       "      <td>school closures</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9955 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id                                               text  \\\n",
       "0     1307558525371965442  @narendramodi @rajnathsingh Student ka bhi soa...   \n",
       "1     1247739239879467009  —échale un vistazo a esto…   … a fair piece on...   \n",
       "2     1242046510155653125  Why do think skilling women and girls is impor...   \n",
       "3     1358446499949084675  To reduce the risk of the virus spreading as e...   \n",
       "4     1249740062775902208  I speak for a great many people when i say WE ...   \n",
       "...                   ...                                                ...   \n",
       "9950  1242516037628813314  StayAtHomeSaveLives 21daysLockdown StayAtHome ...   \n",
       "9951  1242746919933415424  If this is true this is heartbreaking StayAtHo...   \n",
       "9952  1276638598813679617  855 Sunset Cove Dr, Winter Haven, FL 33880 3 B...   \n",
       "9953  1243504288661270528  StayAtHomeSaveLives StayHomeStaySafe StayHome ...   \n",
       "9954  1237875841981247488  We’re on track to be like Italy is now. Time t...   \n",
       "\n",
       "                    Claim  Premise  \n",
       "0         school closures        0  \n",
       "1     stay at home orders        0  \n",
       "2     stay at home orders        0  \n",
       "3         school closures        1  \n",
       "4     stay at home orders        0  \n",
       "...                   ...      ...  \n",
       "9950  stay at home orders        0  \n",
       "9951  stay at home orders        0  \n",
       "9952  stay at home orders        0  \n",
       "9953  stay at home orders        0  \n",
       "9954      school closures        0  \n",
       "\n",
       "[9955 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving it as a dataframe\n",
    "formatted_weighted_avg_prediction_data = pd.DataFrame(zip(weighted_avg_original_tweet_id_list, weighted_avg_original_sentence_list, weighted_avg_original_claim_list, weighted_avg_predicted_results), columns=['id', 'text', 'Claim', 'Premise'])\n",
    "formatted_weighted_avg_prediction_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving it as a tsv file\n",
    "os.makedirs('../15_epochs_large_model/ultra_final_test_result', exist_ok=True)\n",
    "formatted_weighted_avg_prediction_data.to_csv('../15_epochs_large_model/ultra_final_test_result/formatted_majority_data.tsv', sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
